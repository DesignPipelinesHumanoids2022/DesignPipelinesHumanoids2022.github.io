<!DOCTYPE HTML>
<!--
	Stellar by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>DADP Humanoids 2022 workshop</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<span class="logo"><img src="images/logo.svg" alt="" /></span>
						<h1>Workshop on <br />  <strong>Development and Design Pipelines – <strong>  <br />
						From first ideas to well-functioning robots </h1>
						<p>2022 IEEE-RAS International Conference on Humanoid Robots (Humanoids 2022) <br />
						November 28-30, Ginowan, Okinawa, Japan</p>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#intro" class="active">About the workshop</a></li>
							<li><a href="#topic" class="active">Topics</a></li>							
							<li><a href="#program" class="active">Program</a></li>
							<li><a href="#poster" class="active">Call for Contributions</a></li>
							<li><a href="#organizers">Organizers</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Introduction -->
							<section id="intro" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>About the workshop</h2>
										</header>
										<p align=“justify“>Humanoid and other legged robots are highly complex machines. Even more complex, however, is their development. The iterative process of designing robots includes knowledge from all disciplines within the field of robotics, from mechatronic design towards planning and controls. Similar to the curse of dimensionality in learning and optimization (which may very much be part of the development process as well), there exists a kind of "curse of possibilities" – as paradoxical as that may sound: 
For any one of the more or less complex components and sub-solutions of the robot, there exist a multitude of possible options. Eventually, the design team needs to pick out of those options a set that will work well together, which is a complex combinatorial problem. The design space associated to the development of a new robot is simply vast. Thus, to create and build a humanoid robot, adequate development and design pipelines and principals are required. 
</br></br>
											This workshop addresses this issue by bringing together an interested audience with several experienced speakers and presenters, who share their related insights and give an overview of the design pipelines they use (or have used) to successfully develop humanoid / legged robots or other highly complex machines.</p>
<!-- Link 				
										<ul class="actions">
											<li><a href="generic.html" class="button">Learn More</a></li>
										</ul>

									</div>
									<span class="image"><img src="images/pic01.jpg" alt="" /></span>
-->	
								</div>
							</section>
				
							<section id="topic" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>Topics</h2>
										</header>
										<p>The presenters will share their thoughts about the importance of team coordination and communication, how to define and measure development goals, what level of “readiness” / maturity and optimality is required before starting to build a robot? How about heuristics and intuition? How important is the concept of co-design of mechatronics and controls, and how can the correlated “chicken-or-egg” problem be handled? 
										</br></br>
										The particular addressed topics include</p>

										<ul>
												<li>Mechanical design, motion planning and controls for legged robots</li>
												<li>Co-Design / parallel engineering of mechatronics and controls</li>
												<li>Data-driven approaches / pipelines used for robot design</li>
												<li>Iterative design and optimization techniques applied to the development of new robots</li>
												<li>Software infrastructure / architecture facilitating the design of new robots</li>
												<li>Insights about the importance of team building / coordination / motivation</li>
											</ul> 
									</div>									
								</div>
							</section>

						<!-- First Section -->


						<!-- Second Section -->
							
<section id="program" class="main style1">
			<div class="container">
				<header class="major">
					<h2>Program</h2>
				</header>

					<p>The program of this workshop includes 11 talks and 2 poster sessions.</br>
					Recordings of all talks will be made available after the workshop.</p>

					<div class="table-wrapper">
						<table>
							<thead>
								<tr>
									<th>Time</th>
									<th>Speaker</th>
									<th>Topic</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>8:50 - 9:00 JST </br> </td>
									<td>Organizers</td>
									<td>Welcome and Introduction</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>9:00 - 9:30 JST </br>  </td>
									<td><strong>Talk 1</strong></td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>9:30 - 10:00 JST </br>  </td>
									<td><strong>Talk 2</strong>, </td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>10:00 - 10:30 JST </br>  </td>
									<td><strong>Talk 3</strong>, </td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr>
									<td>10:30 - 11:00 JST </br> </td>
									<td>Coffee break + Poster Session</td>
									<td></td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>11:00 - 11:30 JST </br> </td>
									<td>Talk 4</td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>11:30 - 12:00 JST </br> </td>
									<td>Talk 5</td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr>
									<td>12:00 - 13:30 JST </br> </td>
									<td>Lunch break</td>
									<td></td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>13:30 - 14:00 JST </br> </td>
									<td>Talk 6</td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>14:30 - 15:00 JST </br> </td>
									<td>Talk 7</td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr>
									<td>15:00 - 15:30 JST </br> </td>
									<td>Coffee Break + Poster Session</td>
									<td></td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>15:30 - 16:00 JST </br> </td>
									<td>Talk 8</td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>16:00 - 16:30 JST </br> </td>
									<td>Talk 9</td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>16:30 - 17:00 JST </br> </td>
									<td>Talk 10</td>
									<td>TBA</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
							<tr onClick='toggleRow(this)'>
									<td>17:00 - 17:30 JST </br> </td>
									<td></td>
									<td>Open Discussion + Closing Comments</td>
									<td class='expanded-row-content hide-row'>Abstract.</td>
								</tr>
								<tr>
									<td>17:30 - open end JST </br> </td>
									<td>Organizers</td>
									<td>Informal Gathering and Exchange at Beach</td>
								</tr>
							</tbody>
						</table>
					</div>

					
			</div>
		</section>
<-- Test section
<section id="program3" class="main style1">
			<div class="container">
				<header class="major">
					<h2>Program</h2>
				</header>

					<p>The program of this workshop includes 9 talks in several sessions, and a tutorial session on prediction methods and benchmarking.</br>
					Recordings of all talks are available on the <a href="https://www.youtube.com/playlist?list=PLrLNIllEiqRD89KwUllL5oT2lK0NEpk0z">LHMP YouTube channel</a>.</p>

					<div class="table-wrapper">
						<table>
							<thead>
								<tr>
									<th>Time</th>
									<th>Speaker</th>
									<th>Topic</th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>8:30 - 8:45 am EDT </br> 14:30 - 14:45 CEST</td>
									<td>Organizers</td>
									<td>Welcome and Introduction</td>
								</tr>
								<tr>
									<td></td>
									<td>Blue-sky session</td>
									<td></td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>8:45 - 9:15 am EDT </br> 14:45 - 15:15 CEST</td>
									<td><strong><a href="http://www.iri.upc.edu/people/sanfeliu/">Alberto Sanfeliu</a></strong>, Universitat Politècnica de Catalunya</td>
									<td>Predicting human motion for human-robot interaction & collaboration</td>
									<td class='expanded-row-content hide-row'>Abstract: tbd</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>9:15 - 9:45 am EDT </br> 15:15 - 15:45 CEST</td>
									<td><strong><a href="http://people.rennes.inria.fr/Julien.Pettre/">Julien Pettré</a></strong>, INRIA</td>
									<td>Predicting crowds: scales and data</td>
									<td class='expanded-row-content hide-row'>Abstract: Human trajectory prediction (HTP), which has mainly found applications in robotics, is now also finding points of convergence with the field of predictive crowd simulation (for traffic management in public environments for instance). This convergence accelerates in particular the ongoing transition of crowd simulators from knowledge-based models to data-driven ones. Through the exploration of this new field of applications, this presentation raises the question of the formulation of the prediction problem as we know it, but also of the nature of the data that are used for the modeling. In this presentation, I will give the perspective of the field of crowd simulation on these issues, and present some promising techniques for the acquisition of new data that are based on virtual reality. </td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>9:45 - 10:15 am EDT </br> 15:45 - 16:15 CEST</td>
									<td><strong><a href="https://virtualhumans.mpi-inf.mpg.de/people/pons-moll.html">Gerard Pons-Moll</a></strong>, University of Tübingen</td>
									<td>Virtual Humans — From appearance to behaviour</td>
									<td class='expanded-row-content hide-row'>Abstract: Modelling 3D virtual humans is necessary for VR/AR and to digitally transfer people to digital spaces — often referred to as the metaverse.  
									While there has been significant progress on modelling human appearance (how we look), modelling and capturing fine grained human behaviour in 3D has received much less attention.
									Accurately capturing human interactions with scenes and objects in 3D is challenging due to occlusions, complex poses, ambiguities in reconstructing objects in 3D, and limited recording volumes imposed by multi-view camera setups.
									In this talk, I will describe our recent works to capture and model how we behave and interact with the 3D world around us. I will present HPS, a method to capture and localize humans interacting in large 3D scenes from wearable sensors, as well as BEHAVE a recent dataset and method to capture 3D humans interacting with objects.  
									</td>
								</tr>
								<tr>
									<td>10:15 - 11:00 am EDT </br> 16:15 - 17:00 CEST</td>
									<td>Coffee break</td>
									<td></td>
								</tr>
								<tr>
									<td></td>
									<td>Body and Mind session</td>
									<td></td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>11:00 - 11:30 am EDT </br> 17:00 - 17:30 CEST</td>
									<td><strong><a href="https://cos.northeastern.edu/people/dagmar-sternad/">Dagmar Sternad</a></strong>, Northeastern University</td>
									<td>Predicting actions and interactions: the human perspective</td>
									<td class='expanded-row-content hide-row'>Abstract: Anticipating motion of other agents and objects in the environment is key for successful behavior, both for robots and humans. The ability to predict is a core computational competence necessary for almost all aspects of human behavior, including social, cognitive, perceptual and action contexts. This talk will focus on the human perspective and present several lines of research examining predictive abilities and challenges in humans.

										</br></br>Our recent research investigated this fundamental ability in the context of sensorimotor interactions with a dynamic object: intercepting and catching a flying ball. To examine the developmental trajectory of predictive ability, we assessed participants between 5 and 92 years of age in a suite of custom-developed virtual games that provided millisecond-scale measures of actions in response to the flying ball. Results revealed age-related improvements in predictive motor behavior, with performance reaching adult levels by 12 years of age. This developmental progression provides a behavioral manifestation consistent with recent findings on cerebellar and cortical maturation. 

										</br></br>A second line of research scrutinized how humans continuous interact with dynamically complex objects, such as a cup of coffee. The internal dynamics in such objects creates complex nonlinear interaction forces that can be chaotic and essentially unpredictable for humans. We investigated how humans deal with such scenarios in a virtual environment where human participants transported a cup of coffee’, modeled by a cart and pendulum system. Results showed that humans learnt to simplify the interaction forces that made them more predictable.

										</br></br>A third line of research examined prediction within the motor control system in the context of postural control under perturbations. Catching a ball not only involves finely timed arm and hand movements with respect to the ball, but these rapid arm movements also create perturbing forces that destabilize postural balance. Maintaining upright posture requires anticipatory postural adjustments in trunk muscles that ensures the control of hand movements. We show such subtle adjustments in the context of catching a ball in both healthy and impaired populations.

										</br></br>These different lines of research demonstrate the pervasiveness of accurate prediction at all levels of successful behavior, and also show the challenges that also humans and not only robots face.
</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>11:30 - 12:00 am EDT </br> 17:30 - 18:00 CEST</td>
									<td><strong><a href="http://wpage.unina.it/silrossi/index.html">Silvia Rossi</a></strong>, University of Naples</td>
									<td>Human and context awareness: Toward socially enhanced autonomous capabilities</td>
									<td class='expanded-row-content hide-row'>Abstract: To effectively exploit autonomous capabilities that are socially enhanced, a robot is required to sense its environment but also to understand what happens within it. Human awareness not only concerns the acknowledgment of the person’s position and pose within the environment but also the opportunity to understand the activity that the person is currently performing. For example, robotic personal assistance may be required to recognize the user’s Activities of Daily Living (eating, drinking, cooking, watching TV, using a mobile phone, etc.) or emergencies, such as fall detection. Moreover, the importance of interpreting and recognizing social and non-verbal signals during the interaction is generally well recognized within the social robotics community, but it plays a fundamental role also in service and collaborative robotics. For example, the interpretation of non-verbal cues, such as gaze, posture, and backchannels, can be used in the recognition of the person’s engagement during an interaction, the same could be used to evaluate the person’s discomfort or the disengagement from the current activity caused by the robot’s behavior in the shared environment. In this talk, we will discuss different approaches aiming at achieving socially enhanced autonomous robot behaviors from the interpretation of human behavior.</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>12:00 - 12:30 pm EDT </br> 18:00 - 18:30 CEST</td>
									<td><strong><a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a></strong>, DeepMind</td>
									<td>The surprising diversity of human tool use</td>
									<td class='expanded-row-content hide-row'>Abstract: People use tools every day – from forks and knives to computers and cellphones. Indeed, much of our interaction with the world is modulated by our tools. As a result, understanding how people use tools is critical to safely interacting with humans. In this talk, I will discuss our research into the vast and varied ways that people learn how to use new tools. I will highlight both humans’ rapid adaptivity, but also their surprising rigidity, in the face of new problems. I will also discuss how differences in lived experience, such as growing up with only one hand, can fundamentally alter the ways in which people approach physical problem-solving generally. For robot-human interaction, it will not be enough to model the motion of one ideal human. Instead, a diversity of humans is needed.</td>
								</tr>
								<tr>
									<td>12:30 - 1:45 pm EDT </br> 18:30 - 19:45 CEST</td>
									<td>Lunch break</td>
									<td></td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>1:45 - 2:15 pm EDT </br> 19:45 - 20:15 CEST</td>
									<td><strong><a href="https://ece.illinois.edu/about/directory/faculty/krdc">Katherine Driggs-Campbell</a></strong>, University  of  Illinois</td>
									<td>Inference and prediction for safe interaction </td>
									<td class='expanded-row-content hide-row'>Abstract: Autonomous systems and robots are becoming prevalent in our everyday lives and changing the foundations of our way of life. However, the desirable impacts of autonomy are only achievable if the underlying algorithms can handle the unique challenges humans present. To design safe, trustworthy autonomy, we must transform how intelligent systems interact, influence, and predict human agents. In this talk, we'll discuss how inferring hidden states (e.g., driver traits, pedestrian intent, occluded agents) coupled with robust prediction methods can be used to improve decision-making and control in interactive settings. These methods are used to generate safe interactions between humans and mobile robots (sometimes with guarantees), which are demonstrated on fully equipped test vehicles and mobile robots.</td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>2:15 - 2:45 pm EDT </br> 20:15 - 20:45 CEST</td>
									<td><strong><a href="https://www.borisivanovic.com">Boris Ivanovic</a></strong>, Nvidia</td>
									<td>Effectively integrating prediction within the autonomous vehicle stack</td>
									<td class='expanded-row-content hide-row'>Abstract: tbd</td>
								</tr>
								<tr>
									<td></td>
									<td>Tutorial & Benchmarking session</td>
									<td></td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>2:45 - 3:00 pm EDT </br> 20:45 - 21:00 CEST</td>
									<td><strong><a href="https://thedebugger811.github.io/">Parth Kothari</a></strong>, EPFL</td>
									<td>TrajNet++ update</td>
									<td class='expanded-row-content hide-row'>Link: <a href="https://www.aicrowd.com/challenges/trajnet-a-trajectory-forecasting-challenge">https://www.aicrowd.com/challenges/trajnet-a-trajectory-forecasting-challenge</a></td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>3:00 - 3:15 pm EDT </br> 21:00 - 21:15 CEST</td>
									<td><strong><a href="https://rudenkoandrey.github.io/">Andrey Rudenko</a></strong>, Bosch</td>
									<td>The Atlas Benchmark presentation</td>
									<td class='expanded-row-content hide-row'>Link: tbd</td>
								</tr>
								<tr>
									<td>3:15 - 4:00 pm EDT </br> 21:15 - 22:00 CEST</td>
									<td>Coffee break</td>
									<td></td>
								</tr>
								<tr onClick='toggleRow(this)'>
									<td>4:00 - 4:30 pm EDT </br> 22:00 - 22:30 CEST</td>
									<td><strong><a href="https://www.sanjibanchoudhury.com/">Sanjiban Choudhury</a>, <a href="http://www.cs.cmu.edu/~arunvenk/">Arun Venkatraman</a></strong>, Aurora</td>
									<td>Imitation learning and forecasting: It’s only a game!</td>
									<td class='expanded-row-content hide-row'>Abstract: A core challenge in self-driving is reasoning about how actors on the road interact to affect each other’s motions. Recent advances in machine learning have enabled powerful forecasting techniques that jointly reason about such interactions. However, many of these approaches treat forecasting in isolation from downstream decision making. This leads to a fundamental misalignment in objectives where better forecasts do not necessarily translate into better end-to-end behavior. 

</br></br>In this talk, we will explore a clean-sheet approach to forecasting and decision making that builds on a singular objective – imitate expert human driving. We will present a unified, game-theoretic framework for imitation learning. We will view forecasting as an adversary that discriminates between human and robot driving. Finally, we will show how this framework leads to forecasts that enable human-like, predictable, and interpretable behavior on the road.
</td>
								</tr>
								<tr>
									<td>4:30 - 5:00 pm EDT </br> 22:30 - 23:00 CEST</td>
									<td>Organizers</td>
									<td>Discussion and conclusions</td>
								</tr>
							</tbody>
						</table>
					</div>

					
			</div>
		</section>
     
     -->
							<section id="poster" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>Call for Contributions</h2>
										</header>
								
<p>We invite researchers to submit short papers presenting preliminary results, ongoing works, and demos relevant to the topic described above. The papers will be reviewed by the organizers and acceptance will be based on the quality of the contribution, originality, and relevance to the topics of interest of the workshop.

All accepted contributions will be presented as posters during the poster sessions.</a>
					</br></br>
<strong>Submission procedure<strong>
</br></br>
Submission deadline: TBA
</br></br>
Notification of paper acceptance: TBA
</br></br>
We encourage participants to submit their research in the form of a short (1-2 pages) abstract following template and format guidelines given in the <a href="https://www.humanoids2022.org/submission/paper-submission">Humanoids call for paper instructions</a>.
</br></br>
<!--Papers should be submitted via-->
							</section>
<!-- Get Started -->
							<section id="organizers" class="main special">
								<header class="major spezial">
									<h2>Organizers</h2>
								</header>
				<div class="box alt">
					<div class="row gtr-uniform">
						<div class="col-2">
							<span class="image fit"><img src="images/logo.svg" alt="" /></span>
							<h5> <a href="https://rmc.dlr.de/rm/de/staff/johannes.englsberger/"><strong>Johannes Englsberger</strong>,</br>
									DLR</a></h5>
						</div>
						<div class="col-2">
							<span class="image fit"><img src="images/logo.svg"
									alt="" /></span>
							<h5><a href=https://www.ihmc.us/groups/robert-griffin/"><strong>Robert Griffin</strong>,</br> IHMC</a></h5>
						</div>
						<div class="col-2">
							<span class="image fit"><img src="images/logo.svg" alt="" /></span>
							<h5> <a href="https://rmc.dlr.de/rm/de/staff/robert.schuller/"><strong>Robert Schuller</strong>,</br>DLR</a></h5>
						</div>
						<div class="col-2">
							<span class="image fit"><img src="images/logo.svg" alt="" /></span>
							<h5> <a href="https://rmc.dlr.de/rm/de/staff/jinoh.lee/"><strong>Jinoh Lee</strong>,</br> DLR</a></h5>
						</div>
						<div class="col-2">
							<span class="image fit"><img src="images/logo.svg" alt="" /></span>
							<h5> <a href="https://rmc.dlr.de/rm/de/staff/jinoh.lee/"><strong>Florian Loeffl</strong>,</br> DLR</a></h5>
						</div>
						
					</div>
				</div>
				</br>
				<section  class="main special">
				<header class="major spezial">
				<h2>Get in touch</h2>
				</header>
				<p>If you have any questions, don't hesitate to contact us. Contact e-mail: designpipelines2022@gmail.com.</p>
						</section>
				<!-- Footer -->
					<footer id="footer"> 

						<p class="copyright">&copy; Untitled. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
		<script>
		    const toggleRow = (element) => {
		      element.getElementsByClassName('expanded-row-content')[0].classList.toggle('hide-row');
		      console.log(event);
		    }
		  </script>
	</body>
</html>
